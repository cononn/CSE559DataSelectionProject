Running BAP with embedding: catELMo_4_layers_1024 split: epitope seed: 123 fraction: 1.0
Loading embeddings from: data/pairs7_embeds.pkl
Total pairs: 10500
Embedding dim: 2048
================check Overlapping========================
number of overlapping tcrs:  2
number of overlapping epitopes:  0
train size: 8976 test size: 1524
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 2048)]       0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 2048)]       0                                            
__________________________________________________________________________________________________
dense (Dense)                   (None, 2048)         4196352     input_1[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 2048)         4196352     input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 2048)         8192        dense[0][0]                      
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 2048)         8192        dense_1[0][0]                    
__________________________________________________________________________________________________
dropout (Dropout)               (None, 2048)         0           batch_normalization[0][0]        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 2048)         0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
tf.nn.silu (TFOpLambda)         (None, 2048)         0           dropout[0][0]                    
__________________________________________________________________________________________________
tf.nn.silu_1 (TFOpLambda)       (None, 2048)         0           dropout_1[0][0]                  
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 4096)         0           tf.nn.silu[0][0]                 
                                                                 tf.nn.silu_1[0][0]               
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1024)         4195328     concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 1024)         4096        dense_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 1024)         0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
tf.nn.silu_2 (TFOpLambda)       (None, 1024)         0           dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            1025        tf.nn.silu_2[0][0]               
==================================================================================================
Total params: 12,609,537
Trainable params: 12,599,297
Non-trainable params: 10,240
__________________________________________________________________________________________________
Epoch 1/50
64/64 - 7s - loss: 0.7751 - AUC: 0.6321 - accuracy: 0.5910 - val_loss: 0.6598 - val_AUC: 0.6859 - val_accuracy: 0.6180
Epoch 2/50
64/64 - 5s - loss: 0.6914 - AUC: 0.6963 - accuracy: 0.6395 - val_loss: 0.6436 - val_AUC: 0.6925 - val_accuracy: 0.6225
Epoch 3/50
64/64 - 5s - loss: 0.6346 - AUC: 0.7384 - accuracy: 0.6736 - val_loss: 0.6248 - val_AUC: 0.7084 - val_accuracy: 0.6414
Epoch 4/50
64/64 - 5s - loss: 0.6109 - AUC: 0.7568 - accuracy: 0.6884 - val_loss: 0.6122 - val_AUC: 0.7287 - val_accuracy: 0.6481
Epoch 5/50
64/64 - 5s - loss: 0.5866 - AUC: 0.7731 - accuracy: 0.7009 - val_loss: 0.5912 - val_AUC: 0.7342 - val_accuracy: 0.6682
Epoch 6/50
64/64 - 5s - loss: 0.5798 - AUC: 0.7781 - accuracy: 0.6974 - val_loss: 0.6049 - val_AUC: 0.7330 - val_accuracy: 0.6637
Epoch 7/50
64/64 - 5s - loss: 0.5515 - AUC: 0.8008 - accuracy: 0.7242 - val_loss: 0.6203 - val_AUC: 0.7280 - val_accuracy: 0.6615
Epoch 8/50
64/64 - 5s - loss: 0.5368 - AUC: 0.8098 - accuracy: 0.7316 - val_loss: 0.5980 - val_AUC: 0.7406 - val_accuracy: 0.6682
Epoch 9/50
64/64 - 5s - loss: 0.5219 - AUC: 0.8197 - accuracy: 0.7319 - val_loss: 0.6074 - val_AUC: 0.7422 - val_accuracy: 0.6682
Epoch 10/50
64/64 - 5s - loss: 0.5185 - AUC: 0.8223 - accuracy: 0.7387 - val_loss: 0.6090 - val_AUC: 0.7406 - val_accuracy: 0.6670
Restoring model weights from the end of the best epoch.
Epoch 00010: early stopping
================Performance========================
catELMo_4_layers_1024_epitope_seed_123_fraction_1.0AUC: 0.7101459758475073
precision_recall_fscore_macro (0.6601068376068375, 0.6548556430446195, 0.6520022296195582, None)
acc is 0.6548556430446194
precision1 is 0.6891025641025641
precision0 is 0.6311111111111111
recall1 is 0.5643044619422573
recall0 is 0.7454068241469817
f1macro is 0.6520022296195582
f1micro is 0.6548556430446194
