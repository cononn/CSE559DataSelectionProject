Running BAP with embedding: catELMo_4_layers_1024 split: epitope seed: 4242 fraction: 1.0
Loading embeddings from: data/pairs7_embeds.pkl
Total pairs: 10500
Embedding dim: 2048
================check Overlapping========================
number of overlapping tcrs:  9
number of overlapping epitopes:  0
train size: 8302 test size: 2198
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 2048)]       0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 2048)]       0                                            
__________________________________________________________________________________________________
dense (Dense)                   (None, 2048)         4196352     input_1[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 2048)         4196352     input_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 2048)         8192        dense[0][0]                      
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 2048)         8192        dense_1[0][0]                    
__________________________________________________________________________________________________
dropout (Dropout)               (None, 2048)         0           batch_normalization[0][0]        
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 2048)         0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
tf.nn.silu (TFOpLambda)         (None, 2048)         0           dropout[0][0]                    
__________________________________________________________________________________________________
tf.nn.silu_1 (TFOpLambda)       (None, 2048)         0           dropout_1[0][0]                  
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 4096)         0           tf.nn.silu[0][0]                 
                                                                 tf.nn.silu_1[0][0]               
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1024)         4195328     concatenate[0][0]                
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 1024)         4096        dense_2[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 1024)         0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
tf.nn.silu_2 (TFOpLambda)       (None, 1024)         0           dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1)            1025        tf.nn.silu_2[0][0]               
==================================================================================================
Total params: 12,609,537
Trainable params: 12,599,297
Non-trainable params: 10,240
__________________________________________________________________________________________________
Epoch 1/50
59/59 - 7s - loss: 0.7736 - AUC: 0.6329 - accuracy: 0.5936 - val_loss: 0.6610 - val_AUC: 0.6722 - val_accuracy: 0.6137
Epoch 2/50
59/59 - 5s - loss: 0.6675 - AUC: 0.7109 - accuracy: 0.6509 - val_loss: 0.6431 - val_AUC: 0.6921 - val_accuracy: 0.6378
Epoch 3/50
59/59 - 6s - loss: 0.6261 - AUC: 0.7463 - accuracy: 0.6780 - val_loss: 0.6377 - val_AUC: 0.6987 - val_accuracy: 0.6245
Epoch 4/50
59/59 - 6s - loss: 0.5851 - AUC: 0.7735 - accuracy: 0.7026 - val_loss: 0.6051 - val_AUC: 0.7356 - val_accuracy: 0.6691
Epoch 5/50
59/59 - 6s - loss: 0.5771 - AUC: 0.7806 - accuracy: 0.7077 - val_loss: 0.5971 - val_AUC: 0.7378 - val_accuracy: 0.6751
Epoch 6/50
59/59 - 5s - loss: 0.5472 - AUC: 0.8035 - accuracy: 0.7240 - val_loss: 0.6076 - val_AUC: 0.7388 - val_accuracy: 0.6631
Epoch 7/50
59/59 - 5s - loss: 0.5221 - AUC: 0.8185 - accuracy: 0.7395 - val_loss: 0.5919 - val_AUC: 0.7433 - val_accuracy: 0.6811
Epoch 8/50
59/59 - 5s - loss: 0.5149 - AUC: 0.8224 - accuracy: 0.7367 - val_loss: 0.5837 - val_AUC: 0.7525 - val_accuracy: 0.6931
Epoch 9/50
59/59 - 5s - loss: 0.5045 - AUC: 0.8318 - accuracy: 0.7492 - val_loss: 0.5997 - val_AUC: 0.7469 - val_accuracy: 0.6727
Epoch 10/50
59/59 - 5s - loss: 0.4909 - AUC: 0.8404 - accuracy: 0.7526 - val_loss: 0.5962 - val_AUC: 0.7577 - val_accuracy: 0.6667
Epoch 11/50
59/59 - 5s - loss: 0.4888 - AUC: 0.8422 - accuracy: 0.7561 - val_loss: 0.6114 - val_AUC: 0.7458 - val_accuracy: 0.6847
Epoch 12/50
59/59 - 5s - loss: 0.4735 - AUC: 0.8538 - accuracy: 0.7707 - val_loss: 0.6066 - val_AUC: 0.7537 - val_accuracy: 0.6871
Epoch 13/50
59/59 - 5s - loss: 0.4578 - AUC: 0.8626 - accuracy: 0.7775 - val_loss: 0.5825 - val_AUC: 0.7639 - val_accuracy: 0.6835
Epoch 14/50
59/59 - 5s - loss: 0.4495 - AUC: 0.8675 - accuracy: 0.7806 - val_loss: 0.5983 - val_AUC: 0.7573 - val_accuracy: 0.6895
Epoch 15/50
59/59 - 5s - loss: 0.4421 - AUC: 0.8724 - accuracy: 0.7865 - val_loss: 0.6197 - val_AUC: 0.7561 - val_accuracy: 0.6835
Epoch 16/50
59/59 - 5s - loss: 0.4399 - AUC: 0.8740 - accuracy: 0.7880 - val_loss: 0.6194 - val_AUC: 0.7555 - val_accuracy: 0.6992
Epoch 17/50
59/59 - 5s - loss: 0.4289 - AUC: 0.8796 - accuracy: 0.7919 - val_loss: 0.6222 - val_AUC: 0.7539 - val_accuracy: 0.6943
Epoch 18/50
59/59 - 5s - loss: 0.4167 - AUC: 0.8886 - accuracy: 0.8099 - val_loss: 0.6023 - val_AUC: 0.7597 - val_accuracy: 0.6703
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
================Performance========================
catELMo_4_layers_1024_epitope_seed_4242_fraction_1.0AUC: 0.7051616946831474
precision_recall_fscore_macro (0.6487453500730702, 0.6483166515013649, 0.6480630723842276, None)
acc is 0.6483166515013649
precision1 is 0.6567307692307692
precision0 is 0.6407599309153713
recall1 is 0.62147406733394
recall0 is 0.6751592356687898
f1macro is 0.6480630723842276
f1micro is 0.6483166515013649
